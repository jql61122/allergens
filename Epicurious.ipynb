{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2daae35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from scipy.sparse import csr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae51674d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miso-Butter Roast Chicken With Acorn Squash Pa...</td>\n",
       "      <td>['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...</td>\n",
       "      <td>Pat chicken dry with paper towels, season all ...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crispy Salt and Pepper Potatoes</td>\n",
       "      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n",
       "      <td>Preheat oven to 400°F and line a rimmed baking...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanksgiving Mac and Cheese</td>\n",
       "      <td>['1 cup evaporated milk', '1 cup whole milk', ...</td>\n",
       "      <td>Place a rack in middle of oven; preheat to 400...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>['1 cup evaporated milk', '1 cup whole milk', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italian Sausage and Bread Stuffing</td>\n",
       "      <td>['1 (¾- to 1-pound) round Italian loaf, cut in...</td>\n",
       "      <td>Preheat oven to 350°F with rack in middle. Gen...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>['1 (¾- to 1-pound) round Italian loaf, cut in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newton's Law</td>\n",
       "      <td>['1 teaspoon dark brown sugar', '1 teaspoon ho...</td>\n",
       "      <td>Stir together brown sugar and hot water in a c...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>['1 teaspoon dark brown sugar', '1 teaspoon ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>Brownie Pudding Cake</td>\n",
       "      <td>['1 cup all-purpose flour', '2/3 cup unsweeten...</td>\n",
       "      <td>Preheat the oven to 350°F. Into a bowl sift to...</td>\n",
       "      <td>brownie-pudding-cake-14408</td>\n",
       "      <td>['1 cup all-purpose flour', '2/3 cup unsweeten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>Israeli Couscous with Roasted Butternut Squash...</td>\n",
       "      <td>['1 preserved lemon', '1 1/2 pound butternut s...</td>\n",
       "      <td>Preheat oven to 475°F.\\nHalve lemons and scoop...</td>\n",
       "      <td>israeli-couscous-with-roasted-butternut-squash...</td>\n",
       "      <td>['1 preserved lemon', '1 1/2 pound butternut s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>Rice with Soy-Glazed Bonito Flakes and Sesame ...</td>\n",
       "      <td>['Leftover katsuo bushi (dried bonito flakes) ...</td>\n",
       "      <td>If using katsuo bushi flakes from package, moi...</td>\n",
       "      <td>rice-with-soy-glazed-bonito-flakes-and-sesame-...</td>\n",
       "      <td>['Leftover katsuo bushi (dried bonito flakes) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>Spanakopita</td>\n",
       "      <td>['1 stick (1/2 cup) plus 1 tablespoon unsalted...</td>\n",
       "      <td>Melt 1 tablespoon butter in a 12-inch heavy sk...</td>\n",
       "      <td>spanakopita-107344</td>\n",
       "      <td>['1 stick (1/2 cup) plus 1 tablespoon unsalted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13500</th>\n",
       "      <td>Mexican Poblano, Spinach, and Black Bean \"Lasa...</td>\n",
       "      <td>['12 medium to large fresh poblano chiles (2 1...</td>\n",
       "      <td>Lay 4 chiles on their sides on racks of gas bu...</td>\n",
       "      <td>mexican-poblano-spinach-and-black-bean-lasagne...</td>\n",
       "      <td>['12 medium to large fresh poblano chiles (2 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13501 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "0      Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
       "1                        Crispy Salt and Pepper Potatoes   \n",
       "2                            Thanksgiving Mac and Cheese   \n",
       "3                     Italian Sausage and Bread Stuffing   \n",
       "4                                           Newton's Law   \n",
       "...                                                  ...   \n",
       "13496                               Brownie Pudding Cake   \n",
       "13497  Israeli Couscous with Roasted Butternut Squash...   \n",
       "13498  Rice with Soy-Glazed Bonito Flakes and Sesame ...   \n",
       "13499                                        Spanakopita   \n",
       "13500  Mexican Poblano, Spinach, and Black Bean \"Lasa...   \n",
       "\n",
       "                                             Ingredients  \\\n",
       "0      ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n",
       "1      ['2 large egg whites', '1 pound new potatoes (...   \n",
       "2      ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
       "3      ['1 (¾- to 1-pound) round Italian loaf, cut in...   \n",
       "4      ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
       "...                                                  ...   \n",
       "13496  ['1 cup all-purpose flour', '2/3 cup unsweeten...   \n",
       "13497  ['1 preserved lemon', '1 1/2 pound butternut s...   \n",
       "13498  ['Leftover katsuo bushi (dried bonito flakes) ...   \n",
       "13499  ['1 stick (1/2 cup) plus 1 tablespoon unsalted...   \n",
       "13500  ['12 medium to large fresh poblano chiles (2 1...   \n",
       "\n",
       "                                            Instructions  \\\n",
       "0      Pat chicken dry with paper towels, season all ...   \n",
       "1      Preheat oven to 400°F and line a rimmed baking...   \n",
       "2      Place a rack in middle of oven; preheat to 400...   \n",
       "3      Preheat oven to 350°F with rack in middle. Gen...   \n",
       "4      Stir together brown sugar and hot water in a c...   \n",
       "...                                                  ...   \n",
       "13496  Preheat the oven to 350°F. Into a bowl sift to...   \n",
       "13497  Preheat oven to 475°F.\\nHalve lemons and scoop...   \n",
       "13498  If using katsuo bushi flakes from package, moi...   \n",
       "13499  Melt 1 tablespoon butter in a 12-inch heavy sk...   \n",
       "13500  Lay 4 chiles on their sides on racks of gas bu...   \n",
       "\n",
       "                                              Image_Name  \\\n",
       "0      miso-butter-roast-chicken-acorn-squash-panzanella   \n",
       "1             crispy-salt-and-pepper-potatoes-dan-kluger   \n",
       "2             thanksgiving-mac-and-cheese-erick-williams   \n",
       "3              italian-sausage-and-bread-stuffing-240559   \n",
       "4                     newtons-law-apple-bourbon-cocktail   \n",
       "...                                                  ...   \n",
       "13496                         brownie-pudding-cake-14408   \n",
       "13497  israeli-couscous-with-roasted-butternut-squash...   \n",
       "13498  rice-with-soy-glazed-bonito-flakes-and-sesame-...   \n",
       "13499                                 spanakopita-107344   \n",
       "13500  mexican-poblano-spinach-and-black-bean-lasagne...   \n",
       "\n",
       "                                     Cleaned_Ingredients  \n",
       "0      ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...  \n",
       "1      ['2 large egg whites', '1 pound new potatoes (...  \n",
       "2      ['1 cup evaporated milk', '1 cup whole milk', ...  \n",
       "3      ['1 (¾- to 1-pound) round Italian loaf, cut in...  \n",
       "4      ['1 teaspoon dark brown sugar', '1 teaspoon ho...  \n",
       "...                                                  ...  \n",
       "13496  ['1 cup all-purpose flour', '2/3 cup unsweeten...  \n",
       "13497  ['1 preserved lemon', '1 1/2 pound butternut s...  \n",
       "13498  ['Leftover katsuo bushi (dried bonito flakes) ...  \n",
       "13499  ['1 stick (1/2 cup) plus 1 tablespoon unsalted...  \n",
       "13500  ['12 medium to large fresh poblano chiles (2 1...  \n",
       "\n",
       "[13501 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the csv\n",
    "\n",
    "raw = pd.read_csv('recipes.csv', index_col=0)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5176b6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miso-butter roast chicken with acorn squash pa...</td>\n",
       "      <td>['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crispy salt and pepper potatoes</td>\n",
       "      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thanksgiving mac and cheese</td>\n",
       "      <td>['1 cup evaporated milk', '1 cup whole milk', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian sausage and bread stuffing</td>\n",
       "      <td>['1 (¾- to 1-pound) round italian loaf, cut in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newton's law</td>\n",
       "      <td>['1 teaspoon dark brown sugar', '1 teaspoon ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>brownie pudding cake</td>\n",
       "      <td>['1 cup all-purpose flour', '2/3 cup unsweeten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>israeli couscous with roasted butternut squash...</td>\n",
       "      <td>['1 preserved lemon', '1 1/2 pound butternut s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>rice with soy-glazed bonito flakes and sesame ...</td>\n",
       "      <td>['leftover katsuo bushi (dried bonito flakes) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>spanakopita</td>\n",
       "      <td>['1 stick (1/2 cup) plus 1 tablespoon unsalted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13500</th>\n",
       "      <td>mexican poblano, spinach, and black bean \"lasa...</td>\n",
       "      <td>['12 medium to large fresh poblano chiles (2 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13501 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "0      miso-butter roast chicken with acorn squash pa...   \n",
       "1                        crispy salt and pepper potatoes   \n",
       "2                            thanksgiving mac and cheese   \n",
       "3                     italian sausage and bread stuffing   \n",
       "4                                           newton's law   \n",
       "...                                                  ...   \n",
       "13496                               brownie pudding cake   \n",
       "13497  israeli couscous with roasted butternut squash...   \n",
       "13498  rice with soy-glazed bonito flakes and sesame ...   \n",
       "13499                                        spanakopita   \n",
       "13500  mexican poblano, spinach, and black bean \"lasa...   \n",
       "\n",
       "                                             ingredients  \n",
       "0      ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...  \n",
       "1      ['2 large egg whites', '1 pound new potatoes (...  \n",
       "2      ['1 cup evaporated milk', '1 cup whole milk', ...  \n",
       "3      ['1 (¾- to 1-pound) round italian loaf, cut in...  \n",
       "4      ['1 teaspoon dark brown sugar', '1 teaspoon ho...  \n",
       "...                                                  ...  \n",
       "13496  ['1 cup all-purpose flour', '2/3 cup unsweeten...  \n",
       "13497  ['1 preserved lemon', '1 1/2 pound butternut s...  \n",
       "13498  ['leftover katsuo bushi (dried bonito flakes) ...  \n",
       "13499  ['1 stick (1/2 cup) plus 1 tablespoon unsalted...  \n",
       "13500  ['12 medium to large fresh poblano chiles (2 1...  \n",
       "\n",
       "[13501 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A few of the columns are unnecessary - just taking the two we need and making everything lowercase for consistency\n",
    "df = raw[['Title', 'Cleaned_Ingredients']]\n",
    "df = df.rename(columns={'Title': 'name', 'Cleaned_Ingredients': 'ingredients'})\n",
    "df = df.apply(lambda x: x.str.lower())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10429153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define a list of nuts to which I am allergic and a simple function to determine if any of them are\n",
    "# present in a string \n",
    "\n",
    "allergens = ['walnut', 'pecan', 'macadamia', 'hazelnut', 'brazil nut', 'wal nut']\n",
    "\n",
    "def find_allergens(string):\n",
    "    return any(word in string for word in allergens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2632d3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    12676\n",
       "True       825\n",
       "Name: allergen, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label the data in new column 'allergen' that shows True when an allergen is present and False otherwise\n",
    "# On initial observation is that only 825 of 13501 entries contain an allergen (~6%) so the dataset is somewhat skewed\n",
    "# That may present issues later on that we could try to address with resampling or other methods\n",
    "\n",
    "df['allergen'] = df.ingredients.apply(lambda x: find_allergens(x))\n",
    "df.allergen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143d9647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>allergen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>nut butter granola bars</td>\n",
       "      <td>['2 cups raw nuts (such as almonds, walnuts, p...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>chocolate zucchini cake</td>\n",
       "      <td>['2 1/4 cups sifted all purpose flour', '1/2 c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>swiss chard pasta with toasted hazelnuts and p...</td>\n",
       "      <td>['¼ cup hazelnuts', '1 pound bow tie pasta (fa...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>pear and hazelnut frangipane tart</td>\n",
       "      <td>['1 cup hazelnuts, toasted, loose skins rubbed...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tahini-walnut magic shell</td>\n",
       "      <td>['¼ cup raw walnuts', '3 oz. white chocolate, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13477</th>\n",
       "      <td>frisée and endive salad with warm brussels spr...</td>\n",
       "      <td>['3 tablespoons white-wine vinegar', '2 tables...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>hazelnut-butter cookies with mini chocolate chips</td>\n",
       "      <td>['1 1/2 cups all purpose flour', '3/4 teaspoon...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13492</th>\n",
       "      <td>cornmeal pancakes with honey-pecan butter</td>\n",
       "      <td>['1/2 cup (1 stick) unsalted european-style bu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>ginger-pecan roulade with honey-glazed pecans</td>\n",
       "      <td>['1/2 stick (1/4 cup) unsalted butter, melted,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>brownie pudding cake</td>\n",
       "      <td>['1 cup all-purpose flour', '2/3 cup unsweeten...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>825 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "62                               nut butter granola bars   \n",
       "69                               chocolate zucchini cake   \n",
       "70     swiss chard pasta with toasted hazelnuts and p...   \n",
       "81                     pear and hazelnut frangipane tart   \n",
       "103                            tahini-walnut magic shell   \n",
       "...                                                  ...   \n",
       "13477  frisée and endive salad with warm brussels spr...   \n",
       "13480  hazelnut-butter cookies with mini chocolate chips   \n",
       "13492          cornmeal pancakes with honey-pecan butter   \n",
       "13494      ginger-pecan roulade with honey-glazed pecans   \n",
       "13496                               brownie pudding cake   \n",
       "\n",
       "                                             ingredients  allergen  \n",
       "62     ['2 cups raw nuts (such as almonds, walnuts, p...      True  \n",
       "69     ['2 1/4 cups sifted all purpose flour', '1/2 c...      True  \n",
       "70     ['¼ cup hazelnuts', '1 pound bow tie pasta (fa...      True  \n",
       "81     ['1 cup hazelnuts, toasted, loose skins rubbed...      True  \n",
       "103    ['¼ cup raw walnuts', '3 oz. white chocolate, ...      True  \n",
       "...                                                  ...       ...  \n",
       "13477  ['3 tablespoons white-wine vinegar', '2 tables...      True  \n",
       "13480  ['1 1/2 cups all purpose flour', '3/4 teaspoon...      True  \n",
       "13492  ['1/2 cup (1 stick) unsalted european-style bu...      True  \n",
       "13494  ['1/2 stick (1/4 cup) unsalted butter, melted,...      True  \n",
       "13496  ['1 cup all-purpose flour', '2/3 cup unsweeten...      True  \n",
       "\n",
       "[825 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick eyeball of the data listed as containing allergens - looks reasonable\n",
    "df[df['allergen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3806ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I define our variables for the model. Since I will be using a Random Forest first, I start by vectorizing\n",
    "# the names of the recipes and then split them into train, validation, and test sets in a 60/20/20 ratio.\n",
    "# The training data will be used to train the model, the validation data will be used to evaluate the model and\n",
    "# subsequently tweak the parameters, and the test data will be used to evaluate the final model\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = [str(x) for x in df.name]\n",
    "X = vectorizer.fit_transform(X)\n",
    "y = df.allergen\n",
    "\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X, y, test_size=0.4, random_state=3)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_remaining, y_remaining, test_size=0.5, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5181b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100 2700 2701 8100 2700 2701\n"
     ]
    }
   ],
   "source": [
    "# Check the sizes of X_train, X_validation, X_test, y_train, y_validation, and y_test\n",
    "\n",
    "print(X_train.shape[0], X_validation.shape[0], X_test.shape[0], y_train.shape[0], y_validation.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904059a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Pct True 5.98%\n",
      "Validation Set Pct True 6.63%\n",
      "Test Set Pct True 6.00%\n"
     ]
    }
   ],
   "source": [
    "# Check that the proportion of True in each y set is roughly similar to the population proportion of ~6%\n",
    "\n",
    "y_train_pct = y_train.sum() / y_train.count()\n",
    "y_validation_pct = y_validation.sum() / y_validation.count()\n",
    "y_test_pct = y_test.sum() / y_test.count()\n",
    "\n",
    "print(\"Training Set Pct True %.2f%%\" % (y_train_pct*100))\n",
    "print(\"Validation Set Pct True %.2f%%\" % (y_validation_pct*100))\n",
    "print(\"Test Set Pct True %.2f%%\" % (y_test_pct*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974e5058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the Random Forest Classifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef0bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we test the model, I define a function to output some key model evaluation statistics\n",
    "# After writing this line I decided to instead just use sklearn's \"classification_report\"\n",
    "\n",
    "def test_model(y_actual, y_predicted):\n",
    "    accuracy = np.mean(y_actual == y_predicted)\n",
    "    precision = precision_score(y_actual, y_predicted)\n",
    "    recall = recall_score(y_actual, y_predicted)\n",
    "    f1 = f1_score(y_actual, y_predicted)\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "    print(f\"Model Precision: {precision}\")\n",
    "    print(f\"Model Recall: {recall}\")\n",
    "    print(f\"Model F1 Score: {f1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ddea371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98      2521\n",
      "        True       0.93      0.52      0.67       179\n",
      "\n",
      "    accuracy                           0.97      2700\n",
      "   macro avg       0.95      0.76      0.82      2700\n",
      "weighted avg       0.96      0.97      0.96      2700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "\n",
    "val_predictions = rf_classifier.predict(X_validation)\n",
    "print(classification_report(y_validation, val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f3942e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98      2521\n",
      "        True       0.93      0.50      0.65       179\n",
      "\n",
      "    accuracy                           0.96      2700\n",
      "   macro avg       0.95      0.75      0.82      2700\n",
      "weighted avg       0.96      0.96      0.96      2700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The model has low recall, which may be a symptom of the skewed nature of the sample.\n",
    "# To attempt to correct this, I apply class weights in a 1:15 ratio since the Trues made up 6% of the population\n",
    "\n",
    "class_weights = {0:1.0, 1: 15}\n",
    "rf_classifier = RandomForestClassifier(class_weight=class_weights)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "val_predictions = rf_classifier.predict(X_validation)\n",
    "print(classification_report(y_validation, val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f845ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.99      0.98      2521\n",
      "        True       0.85      0.54      0.66       179\n",
      "\n",
      "    accuracy                           0.96      2700\n",
      "   macro avg       0.91      0.76      0.82      2700\n",
      "weighted avg       0.96      0.96      0.96      2700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since the class weights actually made the Recall problem worse, now I will try resampling\n",
    "\n",
    "# Start by defining the combination resampling pipeline\n",
    "resampling_pipeline = Pipeline([\n",
    "    ('over_sampler', RandomOverSampler()),\n",
    "    ('under_sampler', RandomUnderSampler()),\n",
    "])\n",
    "\n",
    "# Apply combination resampling to the training data\n",
    "X_resampled, y_resampled = resampling_pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_resampled, y_resampled)\n",
    "val_predictions = rf_classifier.predict(X_validation)\n",
    "print(classification_report(y_validation, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb0bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 16:18:07.321678: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.1993\n",
      "Epoch 2/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0978\n",
      "Epoch 3/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0583\n",
      "Epoch 4/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0374\n",
      "Epoch 5/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0253\n",
      "Epoch 6/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 7/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 8/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0074\n",
      "Epoch 9/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0061\n",
      "Epoch 10/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 11/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 12/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0076\n",
      "Epoch 13/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 14/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 15/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 16/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 17/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0104\n",
      "Epoch 18/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 19/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 20/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c6cd1f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the resampling only improved recall slightly, let's try using Deep Learning via TensorFlow for a more complex model\n",
    "\n",
    "# Since the output of the vectorizer I used earlier is a sparse matrix, I convert to a dense matrix.\n",
    "# This consumes a lot of memory but it should be fine for this amount of data\n",
    "\n",
    "X_train_dense = X_train.toarray()\n",
    "\n",
    "# Now I create and compile the model\n",
    "nn_model = Sequential([\n",
    "    Dense(units = 128, activation = 'relu'),\n",
    "    Dense(units = 64, activation = 'relu'),\n",
    "    Dense(units = 32, activation = 'relu'),\n",
    "    Dense(units = 16, activation = 'relu'),\n",
    "    Dense(units = 8, activation = 'relu'),\n",
    "    Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "nn_model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_dense, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05bb17e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 739us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.98      0.97      2521\n",
      "        True       0.68      0.51      0.59       179\n",
      "\n",
      "    accuracy                           0.95      2700\n",
      "   macro avg       0.82      0.75      0.78      2700\n",
      "weighted avg       0.95      0.95      0.95      2700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's evaluate the model using the validation set\n",
    "\n",
    "X_validation_dense = X_validation.toarray()\n",
    "\n",
    "val_predictions = nn_model.predict(X_validation_dense)\n",
    "val_predictions = (val_predictions >0.5)\n",
    "print(classification_report(y_validation, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5285e5",
   "metadata": {},
   "source": [
    "The recall is still not where I want it to be. As a next step, I will try to source more data so that we can have more \"True\" samples. The below code is draft form and will be altered later once the model is completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22dfe605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.965938541281007\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "test_predictions = rf_classifier.predict(X_test)\n",
    "test_accuracy = np.mean(test_predictions == y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64c3c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to use our model to predict whether a single recipe contains allergens\n",
    "\n",
    "def test_recipe(recipe):\n",
    "    recipe_lowercase = recipe.lower()\n",
    "    vector = vectorizer.transform([recipe_lowercase])\n",
    "    prediction = rf_classifier.predict(vector)    \n",
    "    return recipe + ' likely contains allergens' if prediction[0] else recipe + ' is likely allergen-free!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a072ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farro Salad with Beets, Greens and Feta is likely allergen-free!\n"
     ]
    }
   ],
   "source": [
    "tester = 'Farro Salad with Beets, Greens and Feta'\n",
    "print(test_recipe(tester))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d3bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
